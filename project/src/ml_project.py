# -*- coding: utf-8 -*-
"""ML_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18q_kKZSuC3TN3xvSrMibZs00WdxQpcq7
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder
from sklearn.linear_model import LogisticRegression

!pip install ucimlrepo

df = pd.read_csv('/content/dataset.csv')

df = df.drop('label.1', axis=1)

df.head(10)

import pandas as pd

pd.set_option('display.max_row', 10)
pd.set_option('display.max_column', None)
pd.set_option('display.max_colwidth', None)


display(df)

"""# **Data Understanding**"""

num_rows = len(df)
num_columns = len(df.columns)

print(f"jumlah rows = {num_rows}")
print(f"jumlah columns = {num_columns}")

print(df.duplicated().count())

numerik = df.select_dtypes(include=["int64", "float64"]).columns.tolist()
print(numerik)

selected_features = [
    'URLLength',
    'DomainLength',
    'NoOfSubDomain',
    'IsDomainIP',
    'TLD',
    'TLDLength',
    'URLSimilarityIndex',
    'TLDLegitimateProb',
    'URLCharProb',
    'CharContinuationRate',
    'HasObfuscation',
    'NoOfObfuscatedChar',
    'ObfuscationRatio',
    'LetterRatioInURL',
    'SpacialCharRatioInURL',
    'NoOfOtherSpecialCharsInURL'
]

"""***Exploratory Data Analysis (EDA)***"""

#@title Boxplot "Outlier Detection"

outlier_features = [
    'URLLength',
    'DomainLength',
    'NoOfSubDomain',
    'URLSimilarityIndex',
    'TLDLegitimateProb',
    'URLCharProb',
    'CharContinuationRate',
    'NoOfObfuscatedChar',
    'ObfuscationRatio',
    'LetterRatioInURL',
    'SpacialCharRatioInURL',
    'NoOfOtherSpecialCharsInURL'
]

for col in outlier_features:
    plt.figure()
    plt.boxplot(df[col].dropna())
    plt.title(f'Outlier Detection - {col}')
    plt.xlabel(col)
    plt.ylabel('Value')
    plt.show()

#@title Class Distribution "Distribusi Kelas Phishing vs Legitimate"

df['label'].value_counts().plot(kind='bar')
plt.title('Distribusi Kelas Phishing vs Legitimate')
plt.xlabel('Class')
plt.ylabel('Jumlah Data')
plt.show()

#=========================================================
df_drop = df.select_dtypes(include=['int64', 'float64'])#=
#=========================================================
plt.figure(figsize=(10,8))
sns.heatmap(df_drop.corr(), cmap='coolwarm')
plt.title('Heatmap Korelasi Antar Fitur')
plt.show()

"""# **DATA PREPARATION**

### ***DATA CLEANING***
"""

#@title Missing Values

missing_value = df.isnull().sum()

if missing_value.sum() > 0:
    print("Terdapat missing values pada kolom berikut:\n")
    for i, (col, val) in enumerate(missing_value.items(), start=1):
        if val > 0:
            print(f"{i}. {col} : {val} missing values")
else:
    print("Tidak ada missing values pada seluruh kolom.")

#@title Duplicates

duplicates = df.duplicated().sum()
print(duplicates)

#@title outliers

#-

"""### ***FEATURE ENGINEERING***"""

df_fe = df.copy()

#@title Creating new features

df_fe['SpecialCharRatio'] = (
    df_fe['NoOfOtherSpecialCharsInURL'] / df_fe['URLLength']
)

df_fe['IsComplexURL'] = (
    (df_fe['NoOfSubDomain'] > 2) |
    (df_fe['NoOfURLRedirect'] > 0)
).astype(int)

df_fe['HasFinancialKeyword'] = (
    (df_fe['Bank'] == 1) |
    (df_fe['Pay'] == 1) |
    (df_fe['Crypto'] == 1)
).astype(int)

df_fe['LowContentQualityFlag'] = (
    (df_fe['HasTitle'] == 0) &
    (df_fe['HasDescription'] == 0) &
    (df_fe['HasCopyrightInfo'] == 0)
).astype(int)

display(df_fe)

#@title FEATURE EXTRACTION

if 'Domain' in df_fe.columns:
    df_fe['DomainLength'] = df_fe['Domain'].astype(str).apply(len)

if 'URL' in df_fe.columns:
    df_fe['URLCharLength'] = df_fe['URL'].astype(str).apply(len)

#@title FEATURE SELECTION

df_numeric = df_fe.select_dtypes(include=['int64', 'float64'])
#============================================================
plt.figure(figsize=(12, 10))
sns.heatmap(df_numeric.corr(), cmap='coolwarm')
plt.title('Heatmap Korelasi Antar Fitur')
plt.show()
#============================================================

corr_matrix = df_numeric.corr().abs()
upper = corr_matrix.where(
    np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)
)

to_drop = [
    col for col in upper.columns
    if any(upper[col] > 0.9)
]

df_selected = df_numeric.drop(columns=to_drop)
print("Fitur yang dihapus:", to_drop)
print("Jumlah fitur awal :", df_numeric.shape[1])
print("Jumlah fitur akhir:", df_selected.shape[1])

X = df_selected.drop(columns=['label'])
y = df_selected['label']

print(X.shape)
print(y.shape)

"""# **DATA TRANSFORMATION**"""

df_selected

"""### Standardization, Normalization"""

#@title Definisi Fitur

standard_features = [
    'URLLength', 'DomainLength', 'TLDLength', 'NoOfSubDomain',
    'NoOfObfuscatedChar', 'NoOfEqualsInURL', 'NoOfQMarkInURL',
    'NoOfAmpersandInURL', 'NoOfOtherSpecialCharsInURL',
    'LineOfCode', 'LargestLineLength',
    'NoOfURLRedirect', 'NoOfSelfRedirect',
    'NoOfPopup', 'NoOfiFrame',
    'NoOfImage', 'NoOfCSS', 'NoOfJS',
    'NoOfSelfRef', 'NoOfEmptyRef', 'NoOfExternalRef'
]

normalize_features = [
    'URLSimilarityIndex', 'CharContinuationRate',
    'TLDLegitimateProb', 'URLCharProb',
    'LetterRatioInURL', 'DegitRatioInURL',
    'SpacialCharRatioInURL', 'DomainTitleMatchScore',
    'HasFinancialKeyword'
]

#@title Standarisasi, Normalisasi

scaler_standard = StandardScaler()
scaler_normalize = MinMaxScaler()

df_train = df_fe.copy()

cols_to_drop = ['FILENAME', 'URL', 'Domain', 'Title', 'TLD']
df_train = df_train.drop(columns=cols_to_drop, errors='ignore')

df_train[standard_features] = scaler_standard.fit_transform(
    df_train[standard_features]
)
df_train[normalize_features] = scaler_normalize.fit_transform(
    df_train[normalize_features]
)

df_train = df_train.fillna(0)

print("Total NaN:", df_train.isna().sum().sum())

display(df_train)

#@title One-Hot Encoding

#-

"""# Data Splitting"""

from sklearn.model_selection import train_test_split

X = df_train.drop(columns=['label'])
y = df_train['label']

X_train, X_temp, y_train, y_temp = train_test_split(
    X,
    y,
    test_size=0.30,
    stratify=y,
    random_state=42
)

X_val, X_test, y_val, y_test = train_test_split(
    X_temp,
    y_temp,
    test_size=0.50,   # 15% test, 15% validation
    stratify=y_temp,
    random_state=42
)

print("Train size:", X_train.shape)
print("Validation size:", X_val.shape)
print("Test size:", X_test.shape)

display(X)

"""# **MODELING**"""

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.linear_model import LogisticRegression

logreg_baseline = LogisticRegression(
    C=1.0,
    solver='lbfgs',
    max_iter=100,
    random_state=42
)

logreg_baseline.fit(X_train, y_train)
#===
y_pred_train = logreg_baseline.predict(X_train)

print("=== Hasil Evaluasi (Training Set) ===")
print(f"Akurasi: {accuracy_score(y_train, y_pred_train):.4f}")
print("\nClassification Report:")
print(classification_report(y_train, y_pred_train))
print("Confusion Matrix:")
print(confusion_matrix(y_train, y_pred_train))

# ===
y_pred_val = logreg_baseline.predict(X_val)

print("\n=== Hasil Evaluasi (Validation Set) ===")
print(f"Akurasi: {accuracy_score(y_val, y_pred_val):.4f}")
print("\nClassification Report:")
print(classification_report(y_val, y_pred_val))
print("Confusion Matrix:")
print(confusion_matrix(y_val, y_pred_val))


# ===
y_pred_test = logreg_baseline.predict(X_test)

print("\n=== Hasil Evaluasi Akhir (Test Set) ===")
print(f"Akurasi: {accuracy_score(y_test, y_pred_test):.4f}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred_test))
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_test))

from sklearn.model_selection import train_test_split

X = df_train.drop(columns=['label'])
y = df_train['label']

X_train, X_temp, y_train, y_temp = train_test_split(
    X,
    y,
    test_size=0.30,
    stratify=y,
    random_state=42
)

X_val, X_test, y_val, y_test = train_test_split(
    X_temp,
    y_temp,
    test_size=0.50,   # 15% validation, 15% test
    stratify=y_temp,
    random_state=42
)

print("Train size:", X_train.shape)
print("Validation size:", X_val.shape)
print("Test size:", X_test.shape)

from xgboost import XGBClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

xgb_model = XGBClassifier(
    objective='binary:logistic',
    eval_metric='logloss',
    n_estimators=100,
    max_depth=10,
    learning_rate=0.1,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42
)

param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [6, 10],
    'learning_rate': [0.05, 0.1],
    'subsample': [0.8],
    'colsample_bytree': [0.8]
}

grid_search = GridSearchCV(
    estimator=xgb_model,
    param_grid=param_grid,
    scoring='accuracy',
    cv=3,
    n_jobs=-1,
    verbose=1
)

grid_search.fit(X_train, y_train)

best_xgb_model = grid_search.best_estimator_
print("Best Parameters:", grid_search.best_params_)

y_pred_train = best_xgb_model.predict(X_train)

print("\n=== Evaluasi Training Set ===")
print(f"Akurasi: {accuracy_score(y_train, y_pred_train):.4f}")
print(classification_report(y_train, y_pred_train))
print("Confusion Matrix:")
print(confusion_matrix(y_train, y_pred_train))

y_pred_val = best_xgb_model.predict(X_val)

print("\n=== Evaluasi Validation Set ===")
print(f"Akurasi: {accuracy_score(y_val, y_pred_val):.4f}")
print(classification_report(y_val, y_pred_val))
print("Confusion Matrix:")
print(confusion_matrix(y_val, y_pred_val))

y_pred_test = best_xgb_model.predict(X_test)

print("\n=== Evaluasi Test Set (FINAL) ===")
print(f"Akurasi: {accuracy_score(y_test, y_pred_test):.4f}")
print(classification_report(y_test, y_pred_test))
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_test))

importance = best_xgb_model.feature_importances_

# Buat DataFrame
feature_importance_df = pd.DataFrame({
    'Feature': X_train.columns,
    'Importance': importance
}).sort_values(by='Importance', ascending=False)

# Ambil Top 20 agar plot terbaca
top_features = feature_importance_df.head(20)

# Plot
plt.figure(figsize=(10, 6))
plt.barh(top_features['Feature'], top_features['Importance'])
plt.gca().invert_yaxis()
plt.xlabel("Feature Importance (Gain)")
plt.title("Top 20 Feature Importance - XGBoost")
plt.tight_layout()
plt.show()

#@title Implementasi DeepLearning + Evaluasi

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import time
import numpy as np

input_dim = X_train.shape[1]

early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=5,
    restore_best_weights=True
)

model_dl = keras.Sequential([
    layers.Dense(128, activation='relu', input_shape=(input_dim,)),
    layers.Dropout(0.5),
    layers.Dense(64, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(1, activation='sigmoid')
])

model_dl.compile(
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

start_train = time.time()

history = model_dl.fit(
    X_train,
    y_train,
    validation_data=(X_val, y_val),
    epochs=50,
    batch_size=32,
    callbacks=[early_stopping],
    verbose=1
)

end_train = time.time()
training_time = end_train - start_train

start_infer = time.time()

y_pred_prob = model_dl.predict(X_test)
y_pred = (y_pred_prob >= 0.5).astype(int).ravel()

end_infer = time.time()
inference_time = end_infer - start_infer

accuracy  = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall    = recall_score(y_test, y_pred)
f1        = f1_score(y_test, y_pred)

print("\n=== Evaluasi Model Deep Learning (Test Set) ===")
print(f"Accuracy      : {accuracy:.4f}")
print(f"Precision     : {precision:.4f}")
print(f"Recall        : {recall:.4f}")
print(f"F1-Score      : {f1:.4f}")
print(f"Training Time : {training_time:.2f} detik")
print(f"Inference Time: {inference_time:.4f} detik")

plt.figure()
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training & Validation Loss per Epoch')
plt.legend()
plt.show()

plt.figure()
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training & Validation Accuracy per Epoch')
plt.legend()
plt.show()